---

# ğŸ“˜ CAP Theorem

---

## ğŸ” What Is the CAP Theorem?

The **CAP Theorem** (also called **Brewerâ€™s Theorem**) states that:

> **In any distributed data system, you can only guarantee two out of the following three properties at the same time:**
>
> * **C**: Consistency
> * **A**: Availability
> * **P**: Partition Tolerance

---

## ğŸ“– The Three Properties Explained

### 1. ğŸ”„ **Consistency (C)**

All nodes **see the same data at the same time**.

> After a write, all future reads reflect that writeâ€”across all nodes.

ğŸ“Œ Example: If you write `x = 5` on one node, reading `x` from any other node instantly gives you `5`.

#####   What is a Node?
A node is an individual computing device or process that participates in a network or distributed system.
It could be:
- A server
- A virtual machine
- A container
- Or even a process within a machine

Each node typically stores data, processes requests, or communicates with other nodes 
Examples:
- Database nodes: Store and serve parts of the database (e.g., MongoDB shards, Cassandra nodes)
- Application nodes: Run business logic (e.g., Node.js/Java service)
- Cache nodes: Handle in-memory data (e.g., Redis instances)
- Load balancer nodes: Route traffic


---

### 2. ğŸŸ¢ **Availability (A)**

The system **always responds** to requestsâ€”even if the answer is outdated or partial.

> Every request gets a (non-error) response, without guaranteeing it's the most recent.

ğŸ“Œ Example: During a network issue, a node can still respond, but maybe with stale data.

---

### 3. ğŸŒ **Partition Tolerance (P)**

The system **continues to operate despite communication breakdowns** between parts of the system.

ğŸ“Œ Example: In case of a network failure between two data centers, both still keep working.

---

## ğŸ“Œ Important Constraint

### ğŸ‘‰ **In a network partition, you must choose between consistency and availability.**

Why?

Because **you canâ€™t communicate across the partition**. So you must:

* Either **wait** (lose availability) to maintain consistency, or
* **Respond anyway** (lose consistency) to stay available.

---

## ğŸ“Š Visual Summary

```
       +---------------------------+
       |       CAP Theorem        |
       +---------------------------+
        |       |        |
        C       A        P
       / \     / \      / \
      /   \   /   \    /   \
     âœ“     âœ— âœ“     âœ—  âœ“     âœ—

You can only pick 2 out of the 3.
```

---

## ğŸ› ï¸ Real-World Examples

| System Type | Picks                                       | Behavior                                                              |
| ----------- | ------------------------------------------- | --------------------------------------------------------------------- |
| **CP**      | Consistency + Partition Tolerance           | Consistent, but may reject requests (not always available)            |
| **AP**      | Availability + Partition Tolerance          | Always responds, but data might be stale                              |
| **CA**      | Consistency + Availability (âš ï¸ Unrealistic) | Works only **if there is no partition**, i.e., perfect network (rare) |

> You *cannot* build a CA system that is also partition-tolerantâ€”**and all real-world systems must tolerate partitions**.

---

## ğŸ§  CAP in Interview Context

**Scenario:** "Design a distributed cache system."
You can say:

> "Since caching systems favor high availability and performance, Iâ€™d choose **AP** over **CP**, accepting eventual consistency."


## ğŸ§ª Example Thought Exercise

### Let's say:

You have a system with two nodes in different data centers.
Network breaks â†’ Partition happens.

Now you must choose:

* If you want **Consistency**, Node A will **refuse writes** until Node B is back.
* If you want **Availability**, Node A will accept writes, **risking divergence** from Node B.

---

## ğŸ“š Summary

| Term            | Meaning                                                                 |
| --------------- | ----------------------------------------------------------------------- |
| **C**           | All nodes see the same data                                             |
| **A**           | System responds to every request                                        |
| **P**           | System tolerates network failure                                        |
| **CAP Theorem** | You can only guarantee **two** of the three in a **partitioned system** |

---

## ğŸš€ Designer's Responsibility

* Choose the trade-offs based on system goals.
* In most real-world systems, **partition tolerance is a must**, so the real decision is:
  â†’ **Consistency vs. Availability**

---

---

# ğŸ“˜ PACELC Theorem 

---

## ğŸ” 1. Background: From CAP to PACELC

> In case of a **network partition (P)**, a distributed system **must choose** between:

* **Consistency (C)** â€“ all nodes see the same data at the same time
* **Availability (A)** â€“ every request gets a response (might not be the latest)

ğŸ“Œ So, **CAP only talks about trade-offs during a failure (partition).**

But what about when there's **no failure**?

---

## ğŸŒŸ 2.  PACELC

> **If** there is a **Partition (P)**, a system must choose between **Availability (A)** and **Consistency (C)**
> **Else (E)**, when the system is running normally, it must choose between **Latency (L)** and **Consistency (C)**

So the full expansion is:

```
PACELC = If P then A or C; Else L or C
```

ğŸ” It covers both:

* **Failure-time tradeoffs (Partition scenario)**
* **Normal operation tradeoffs (Latency vs. Consistency)**

---

## ğŸ§± 3. Breaking Down PACELC

| Component | Stands for   | Meaning                                        |
| --------- | ------------ | ---------------------------------------------- |
| **P**     | Partition    | A network failure occurs between nodes         |
| **A**     | Availability | System continues to operate and serve requests |
| **C**     | Consistency  | All users see the same data                    |
| **E**     | Else         | Normal state â€“ no partition                    |
| **L**     | Latency      | Fast response time                             |
| **C**     | Consistency  | Same as above â€“ correct and same view of data  |

---

## ğŸ§® 4. Why is this important?

CAP is **incomplete** â€” it only explains behavior **during failure**.
But systems **always** face trade-offs, even when **there is no failure**.

PACELC is more practical for **real-world system design**.

---

## ğŸ› ï¸ 5. PACELC in Action: Example Systems

| System                | PACELC Classification | Explanation                                                                                       |
| --------------------- | --------------------- | ------------------------------------------------------------------------------------------------- |
| **Cassandra**         | PA/EL                 | Chooses Availability over Consistency during partition, and Low Latency over Consistency normally |
| **DynamoDB**          | PA/EL                 | Prioritizes availability and low latency                                                          |
| **MongoDB**           | PA/EC                 | Can be tuned either way; often consistency is prioritized                                         |
| **HBase**             | PC/EC                 | Prioritizes Consistency always                                                                    |
| **Cosmos DB (Azure)** | Tunable               | You can configure between consistency levels (strong, bounded staleness, etc.)                    |

---

## ğŸ“ˆ 6. Real-life Analogy

Imagine a **group chat app**:

* If a **server is disconnected** (partition):

  * Do we **let users continue chatting** (availability)?
  * Or **stop and sync data** to ensure everyone sees the same thing (consistency)?

* If all is working fine:

  * Do we **return fast replies** (latency)?
  * Or **wait for every message to be confirmed by all replicas** (consistency)?

PACELC asks: **What do you want when the network is fine too?**

---

## ğŸ§  7. Why This Matters in Interviews

PACELC gives depth to your answers.

Instead of just saying:

> â€œThis system is AP in CAP terms.â€

You can say:

> â€œThis system is **PA/EL**, meaning it chooses availability during partitions and favors low latency otherwise.â€

ğŸ¯ Shows you understand both **failure** and **non-failure** time tradeoffs.

---

## ğŸ§ª 8. Summary Table

| Scenario       | Trade-off |
| -------------- | --------- |
| ğŸ›‘ Partition   | A vs. C   |
| âœ… No Partition | L vs. C   |

---

